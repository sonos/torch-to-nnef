# 2. <span style="color:#6666aa">**:material-archive-search:**</span> NNEF archive composition

The NNEF generated by our [getting-started](/tutos/1_getting_started) (and all `torch_to_nnef` export) respect most of the format defined by the
[![Khronos](/img/khronos.png){: style="width: 120px;margin:0;"}](https://www.khronos.org/) in [their specification](https://registry.khronos.org/NNEF/specs/1.0/nnef-1.0.5.html).

In fact this package use  their [tools](https://github.com/KhronosGroup/NNEF-Tools) to perform last serialization part of the export.
That's why, most information you may need to understand this format is available
in [their specification](https://registry.khronos.org/NNEF/specs/1.0/nnef-1.0.5.html).
This page provides a quick glimpse with emphasis on key elements/differences, to allow you to
easily navigate it.

As shown in the 1st tutorial, export step create a `${MY_MODEL_NAME}.nnef.tgz` archive.
This is really just a classical `tar` archive with `gzip` compression option.

!!! info

    **tract** itself is agnostic to specific archive or 'compression' format and as long as you provide a
    `graph.nnef` text file and related `.dat` files it should be possible to run it
    through tract. In fact tract is even able to take the model from a bit stream given
    proper interface call.

Since it's just an archive you can just extract it:

```bash
mkdir vit_b_16_nnef_dir
cd vit_b_16_nnef_dir
tar -xvzf ../vit_b_16.nnef.tgz
ls -l
```

You should see a list of `.dat` binary files each correspond to a specific 'parameter' tensor from the ViT neural
network exported, and a `graph.nnef` that contains the textual representation of the graph.

## Graph.nnef

Let's start by looking at the `graph.nnef`.

```c++ title="graph.nnef"
version 1.0;

extension tract_registry tract_core;

fragment tract_core_properties(
) -> (properties: (string, tensor<scalar>)[])
{
  properties = [
    ("tract_target_version", "0.21.13"),
    ("torch_to_nnef_version", "0.18.6"),
//...
    ("export_cmd", "getting_started.py")
  ];
}

fragment tract_gelu( x: tensor<scalar> ) -> ( y: tensor<scalar> )
{
    y = 0.5 * x * ( 1.0 + tract_core_erf(x * 0.7071067811865475));
}

// ...

graph network(input) -> (output)
{
    input = tract_core_external(shape = [1, 3, 224, 224], datum_type = 'f32');
    class_token = variable<scalar>(label = 'class_token', shape = [1, 1, 768]);
//...
    output = linear(select0, heads_head_weight, heads_head_bias_aligned_rank_expanded);

}
```

First we observe the `extension`s, in our case some of the operators used later are specific to tract,
so the tract registry called `tract_core` is needed. In tract there is various registry for different purposes:
`tract_core` (all classical operators in tract), `tract_transformers` that hold some operators specific to transformers,
`tract_onnx` (operators very specific happening in ONNX), `tract_extra` that is specific to peculiar operators such as `exponential unit norm`,
`tract_resource` to load custom variables inside your graph...
Those are added automatically by `torch_to_nnef` except if you use [custom operators](/docs/tutos/8_custom_operator.md).

After that we see a set of `fragment`s you can think of those as [pure functions](https://en.wikipedia.org/wiki/Pure_function), for
most of them (there is few exception like if there is `scan` operator but that a good
approximate). `tract_gelu` is interesting because it is replaced on fly by `gelu` specific
operator if it exist in selected registries and for your hardware.

Finally there is the `network` which is the main entry point that will describe the
inference computations to perform from inputs to outputs by calling operators and fragments,
and assigning the result in temporary `variables`.

- `tract_core_external` is like `external` from NNEF original spec but with data type specification,
    allowing fine grained definition of what is expected.
- `variable<scalar>` is the standard way to load parameter tensor as described in NNEF spec. label name
directly match with the `${label_name}.dat` file that will be loaded.

!!! info

    As of today graph is mostly 'flat' with exception of few fragments.
    `torch.nn.Module` structure are not maintained in the final NNEF, so
    there is repetitions in the control flow expressed here.

    Nothing, prevent us to further factorize the graph in the future,
    beyond simplicity of this package codebase, as this graph representation
    is NOT the final optimized graph that tract will run but rather the
    blueprint.

## .dat files

![hexadecimal .dat repr](/img/hexa_dat.png)

We follow the `.dat` format specification defined in [the Khronos spec](https://registry.khronos.org/NNEF/specs/1.0/nnef-1.0.5.html#tensor-data-format),
including support for q8 quantization.
We also leverage the flexibility left to define new formats, by example:
`Q4_0` .dat files in a format that is close to isolated [GGML_TYPE_Q4_0](https://github.com/ggml-org/ggml/blob/master/docs/gguf.md),
and can be exported to tract with our package seamlessly as explained
in the [quantization tutorial](/docs/tutos/6_quantization.md).
